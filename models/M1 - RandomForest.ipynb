{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Asegurar la instalación de pandas\n",
    "# try:\n",
    "import pandas as pd\n",
    "# except ImportError:\n",
    "#     print(\"pandas is not installed. Installing...\")\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"--user\"])\n",
    "#     import pandas as pd\n",
    "\n",
    "# Asegurar la instalación de matplotlib\n",
    "# try:\n",
    "import matplotlib.pyplot as plt\n",
    "# except ImportError:\n",
    "#     print(\"matplotlib is not installed. Installing...\")\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\", \"--user\"])\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurar la instalación de ydata-profiling\n",
    "# try:\n",
    "#     from ydata_profiling import ProfileReport\n",
    "# except ImportError:\n",
    "#     print(\"ydata-profiling is not installed. Installing...\")\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ydata-profiling\", \"--user\"])\n",
    "#     from ydata_profiling import ProfileReport\n",
    "# try:\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "# except ImportError:\n",
    "#     print(\"sklearn was not installed. Installing now...\")\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\", \"--user\"])\n",
    "from sklearn.model_selection import train_test_split    \n",
    "# %pip install ydata-profiling\n",
    "# %pip install ipywidgets\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['group']\n",
    "X = df.drop(['group', 'Initial_EDSS','Final_EDSS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=100)\n",
    "\n",
    "# Dividir X_temp y y_temp en conjuntos de validación y prueba\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean = X_train.dropna()\n",
    "y_train_clean = y_train.loc[x_train_clean.index]\n",
    "\n",
    "x_test_clean = X_test.dropna()\n",
    "y_test_clean = y_test.loc[x_test_clean.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=100)\n",
    "rf.fit(x_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_train_pred = rf.predict(x_train_clean)\n",
    "y_rf_test_pred = rf.predict(x_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "rf_train_mse = mean_squared_error(y_train_clean, y_rf_train_pred)\n",
    "rf_train_r2 = r2_score(y_train_clean, y_rf_train_pred)\n",
    "rf_test_mse = mean_squared_error(y_test_clean, y_rf_test_pred)\n",
    "rf_test_r2 = r2_score(y_test_clean, y_rf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame(['Random Forest', rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()\n",
    "rf_results.columns = ['Method', 'Training MSE', 'Training R2', 'Test MSE', 'TEST R2']\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las clases en los conjuntos de entrenamiento, validación y prueba\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_val = rf.predict(X_val)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Calcular la precisión en los conjuntos de entrenamiento, validación y prueba\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", accuracy_train)\n",
    "print(\"Precisión en el conjunto de validación:\", accuracy_val)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy_test)\n",
    "\n",
    "# Calcular las probabilidades de las clases en el conjunto de validación\n",
    "y_prob_val = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calcular el AUC-ROC\n",
    "auc_roc = roc_auc_score(y_val, y_prob_val)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "\n",
    "# Convertir los valores de y_val a {0, 1}\n",
    "y_val_binary = y_val.apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Calcular el AUC-ROC\n",
    "auc_roc = roc_auc_score(y_val_binary, y_prob_val)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_val_binary, y_prob_val)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
